Started Journal May 1 2023.

This journal will chronical my efforts to create a file tracking program.
    1. Gets the path, file name and hash of files on my computer.
    2. By using the hash I can find identical files.
    3. Keep track of changes to the file. (Maybe last date?)
    4. The input is either a file or directory.

 I have collected a number of different files that may be germain to the 
 effort that may or may not end up in the final version.

  I found the file listings that were made before and after I copied the files
  to the /HOS/learn/python-in-containers/Docs/ directory.  I don't remember
  if the files I found have the original locations of the pdf files.

  If not then the file locations may be found looking at the backups.

  Right now I will be looking for Database books to figure out how to 
  create the Database.  It will have Filename, filepath, and hash.
  I want to be able to find all files that have the same hash. 
  
  The files that have the locations and filename of the old system
  is /home/echeadle/Workspace/AI_Prog/File_Track/documents.

  Name of the app: file_track_app.py
  1. Add table to database. file_hash
  2. Add index to database
  3. Walk the directory tree.
        a. check to see if the filepath exists in database
            if it does check the hash
            if equal skip, if not equal add

 

  Questions:
  1. What is the program for?  To track file changes is the purpose of the Manning Project.
      I want to create a hash for each file so I can tell if I have duplicates. THis is different
      than the purpose of the Manning project. It runs and just updates the time stamp if the 
      hash changes.  I think that would be interesting, but also I want be able to find duplicates
  2. Files have the same hash are duplicates. Right now the program adds files to  the database
     without checking to see if the file is already there. THe problem with checking just the hash
     is that a true duplicate will have the same hash but if I do not enter it i can't find 
     duplicates.  The next step is to walk the tree, check the hash, if it is the same, then the path
     should be checked. if the hash and the path are the same the file should be skipped.

  May 6,2023
  Today I will create a new file call filetrack.py  THe final version will be file_track.py. This new file
  will be them minimum viable product.  It will start with the skeleton cmdline version but it will build
  up one function at a time. To start, it will create the database, table and index. Next
  it will take a folder as an argument (it will be a default folder)


  Lesson learned, in the skeleton when you add an argument like:
        parser.add_argument('-a', '--arg',
                        help='A named string argument',
                        metavar='str',
                        type=str,
                        default='')

       In the main function
            args = get_args()
            str_arg = args.arg  <<<---- This must matchthe --arg so if it changed this changes

 The file walk code was broken, I was walking subfolders as well which caused issues with duplicating
 files.  The code in filetrack.py is now working properly.

 Next step is add creating the database, table and index. We have to decide what the index should be 
 and what the db is for.  I am thinking the index should be the hash. That way duplicate records can be found
 quickly, we also need a time stamp so if a file is changed we can determine it.  What happens if a file is
 altered and the hash changes?  How is it handled in the database.

 May 7, 2023
 Continue to set up the Database.  
 Database setup works.
 TODO: Move the varibles to an ini file.  
